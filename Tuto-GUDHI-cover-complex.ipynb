{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathieu CarriÃ¨re, https://mathieucarriere.github.io/website/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi import CoverComplex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will see how to use Gudhi in order to perform topological dimension reduction: we will compute simplicial complex approximations of point cloud / distance matrices. These complexes will be either [Mapper complexes](https://diglib.eg.org/handle/10.2312/SPBG.SPBG07.091-100) or [Graph Induced complexes](http://web.cse.ohio-state.edu/~dey.8/GIC/gic.html). Both complexes use covers of the initial space (such as Voronoi partitions or preimages of filter functions), and use these covers to generate simplicial complexes, either by taking the nerve (Mapper) or by checking the presence of colored cliques (Graph Induced). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gudhi can handle both point clouds and distance matrices. Let's start with a point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an example point cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('/home/mcarrier/Github/gudhi/data/points/human.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(X[::2,1], X[::2,0], X[::2,2], s=1)\n",
    "limits = np.array([ax.get_xlim3d(), ax.get_ylim3d(), ax.get_zlim3d()])\n",
    "origin = np.mean(limits, axis=1)\n",
    "radius = 0.5 * np.max(np.abs(limits[:, 1] - limits[:, 0]))\n",
    "x, y, z = origin\n",
    "ax.set_xlim3d([x - radius, x + radius])\n",
    "ax.set_ylim3d([y - radius, y + radius])\n",
    "ax.set_zlim3d([z - radius, z + radius])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the height function to color the complex nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = X[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next provide different configurations for computing cover complexes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Induced complex with a Voronoi partition with 100 randomly sampled germs and Rips graph obtained with automatic threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='gic', input_type='point cloud', cover='voronoi', colors=height, mask=0,\n",
    "    graph=\"rips\", rips_threshold=None, N=100, beta=0., C=10,\n",
    "    voronoi_samples=100, \n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Induced complex with a preimage partition with automatic resolution and Rips graph obtained with automatic threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='gic', input_type='point cloud', cover='functional', colors=height, mask=0,\n",
    "    graph=\"rips\", rips_threshold=None, N=100, beta=0., C=10,\n",
    "    filters=height, resolutions=None, gains=0.,\n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapper complex with a preimage cover with automatic resolution and hierarchical clustering obtained with automatic threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='mapper', input_type='point cloud', cover='functional', colors=height[:,np.newaxis], mask=0,\n",
    "    clustering=None, N=100, beta=0., C=10,\n",
    "    filters=height[:,np.newaxis], filter_bnds=None, resolutions=None, gains=None,\n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapper complex with a preimage cover with automatic resolution from a 2D function and hierarchical clustering obtained with automatic threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt2d = np.hstack([height[:,np.newaxis],X[:,0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='mapper', input_type='point cloud', cover='functional', colors=filt2d, mask=0,\n",
    "    clustering=None, N=100, beta=0., C=10,\n",
    "    filters=filt2d, filter_bnds=None, resolutions=[20,2], gains=None,\n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually process the dataset using only the pairwise distances between points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pairwise_distances(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, color is given by eccentricity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecc = X.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='gic', input_type='distance matrix', cover='functional', colors=ecc, mask=0,\n",
    "    graph=\"rips\", rips_threshold=None, N=100, beta=0., C=10,\n",
    "    filters=ecc, resolutions=None, gains=0.,\n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='gic', input_type='distance matrix', cover='voronoi', colors=ecc, mask=0,\n",
    "    graph=\"rips\", rips_threshold=None, N=100, beta=0., C=10,\n",
    "    voronoi_samples=100, \n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex = CoverComplex(\n",
    "    complex_type='mapper', input_type='distance matrix', cover='functional', colors=ecc[:,np.newaxis], mask=0,\n",
    "    clustering=None, N=100, beta=0., C=10,\n",
    "    filters=ecc[:,np.newaxis], filter_bnds=None, resolutions=None, gains=None,\n",
    "    input_name=\"human\", cover_name=\"coord2\", color_name=\"coord2\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cover complex can now be computed in a single line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cover_complex.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the complex in three different ways with Gudhi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You can use Python package `networkx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = cover_complex.get_networkx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "nx.draw(G, pos=nx.kamada_kawai_layout(G), node_color=[cover_complex.node_info[v][\"colors\"][0] for v in G.nodes()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You can create a DOT file that can be processed later with `neato` to produce a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.print_to_dot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!neato -Tpdf human.dot -o human.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You can create a TXT file that you can process later with our KeplerMapper wrapper to produce a HTML file that you can visualize in browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.print_to_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/mcarrier/Github/gudhi/src/Nerve_GIC/utilities/KeplerMapperVisuFromTxtFile.py -f human.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topological features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various postprocessing one can do on a cover complex. For instance, one can compute the topological features in the complex. For our human shape, the topological features (identified by computing the persistence of the color function on the complex) are the three branches corresponding to the arms and legs (the lower leg correspond to the whole connected component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm, bnd = cover_complex.compute_topological_features(threshold=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = cover_complex.get_networkx()\n",
    "plt.figure(figsize=(8,2))\n",
    "for idx, bd in enumerate(bnd):\n",
    "    plt.subplot(1,len(bnd),idx+1)\n",
    "    nx.draw(G, pos=nx.kamada_kawai_layout(G), \n",
    "            node_color=[1 if node in bd else 0 for node in G.nodes()], node_size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also identify the robust topological features by bootstrapping, and select those associated to 95% confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.bootstrap_topological_features(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = cover_complex.get_distance_from_confidence_level(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnd_boot = [b for idx, b in enumerate(bnd) if np.abs(.5 * (dgm[idx][1][1]-dgm[idx][1][0])) >= dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = cover_complex.get_networkx()\n",
    "plt.figure(figsize=(8,2))\n",
    "for idx, bd in enumerate(bnd_boot):\n",
    "    plt.subplot(1,len(bnd_boot),idx+1)\n",
    "    nx.draw(G, pos=nx.kamada_kawai_layout(G), \n",
    "            node_color=[1 if node in bd else 0 for node in G.nodes()], node_size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, one can identify the coordinates that best explain a topological feature VS the rest of the complex with a Kolmogorov-Smirnov test. In particular, for each topological feature, we can rank the coordinates with respect to their p-values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, coordinate 2 (height) is the one that best distinguishes the leg from the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.compute_differential_coordinates(nodes=bnd[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, coordinate 0 best explains both arms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.compute_differential_coordinates(nodes=bnd[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_complex.compute_differential_coordinates(nodes=bnd[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
